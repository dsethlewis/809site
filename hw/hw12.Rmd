---
title: 'HW #12: SEM II'
author: "Daniel Lewis"
date: "9/30/2020"
output: 
  prettydoc::html_pretty:
    theme: architect
    highlight: github
bibliography: biblio.json
csl: "../apa.csl"
---

## Load Packages

```{r message = F, warning = F}
# Projects
library(here)

# R Markdown
library(knitr)
library(rbbt)
library(kableExtra)

# Statistics
library(psych)
library(lavaan)

# Tidyverse
library(haven)
library(tidyverse)
library(magrittr)
```

## 1. Intercorrelated Measurement Model

### Modeling in R

First, I need to import the covariance matrix for the items. I will also clean it up a bit.

Note: I need to take the absolute value of the data because `lavaan` does not accept negative values in its sample covariance matrices. I believe this should not affect the results by destroying information.

```{r}
tbl.1 <- read_dta(here('data', 'ambcori.dta'))

tbl.1 <- tbl.1[3:length(tbl.1)] %>%
  filter(!is.na(amb1)) %>%
  abs
```

I believe the SEM measurement model is equivalent to a CFA, so I may need to use the `cfa()` function in place of `sem()` to reproduce the LISREL/Stata analysis.^[I looked it up. `sem()` would work identically.] 

I will also standardize the factors to a mean of zero and a variance of one. That's my understanding of what `PH=ST` in LISREL and `var(AMB@1 CD@1 TP@1 HI@1 ANX@1)` in Stata are doing. It also allows `lavaan` to estimate loadings for the first item in each factor instead of using those items as scales.

```{r, warning=FALSE}
mtx.1 <- tbl.1 %>%
  as.matrix %>%
  set_rownames(colnames(.))

chr.1 <- '
    # measurement
    amb =~ amb1 + amb2 + amb3 + amb4 + amb5
    cd =~ cd1 + cd2 + cd3 + cd4
    tp =~ tp1 + tp2 + tp3 + tp4 + tp5
    hi =~ hi1 + hi2 + hi3 + hi4 + hi5 + hi6
    anx =~ anx1 + anx2 + anx3 + anx4 + anx5 + anx6 + anx7 + anx8
'

fit.1 <- cfa(chr.1, sample.cov = mtx.1, sample.nobs = 211, std.lv = T)
```

As a spot test, I'm going to check whether the $\chi^2$ for the R model matches that of the LISREL model.

```{r}
fitMeasures(fit.1, "chisq")
```

Oy, that does not match the $\chi^2 \approx 605$ in the LISREL output. But it's kind of close. I'll check the RMSEA.

```{r}
fitMeasures(fit.1, "rmsea")
```
That's also close, but not exactly right. OK, here's what I'm going to do. I will proceed with the analysis using the results in R but continue to check them against the LISREL output for now.

### Item Loadings in Measurement-Only Model

```{r}
tbl.1.a <- fit.1 %>%
  parameterEstimates(ci = F)

tbl.1.a %>%
  filter(op == "=~") %>%
  kable
```

First, the item loadings are approximately the same to those in LISREL, albeit not identical.

Second, all the item loadings are significant across the board.

Third, however, some of the loadings are worryingly low. TP5 loads on TP with just .18 and ANX2 loads on ANX with just .26.

TP5 is "Faced with daily deadlines at work", while most of the other TP items refer to time pressure *outside* of work. There may be an issue with that.

ANX2 is "Felt as though I might faint", which is both in a different tense than the other items (past vs. present) and is less a core symptom of anxiety than the other items (cf. "upset", "restless", "panicky"). Thus, it's also possible to reason why there might be an issue with that item.

Overall, frankly, few factor loadings exceed the common .7 rule-of-thumb. All these factors and loadings should therefore be interpreted with a grain of salt.

### Factor Correlations

```{r}
chr.1.a <- c("amb", "cd", "tp", "hi", "anx")

tbl.1.a %>%
  filter(op == "~~", lhs %in% chr.1.a, lhs != rhs) %>%
  kable
```

Again, the estimates produced by R are similar, but not identical to, the estimates produced by LISREL. At this point, I will assume that trend continues and focus on the R output from here on.

Our model supposes that, whether through direct or indirect effects, every variable is correlated with every other. The estimates of factor correlations mostly bear that out. With the possible exception of CD and ANX ($\phi_{CD, ANX} \approx .14, p < .1$), every pair of factors is significantly correlated. In addition, AMB and ANX are only weakly correlated ($\phi_{AMB, ANX}\approx.21, p < .05$). But AMB and CD are theoretically most distal from ANX in the model, so this is not really a problem.

We will have to see what happens when these factors are formally introduced to each other in the structural model.

### Modification Indices

Modification indices (MIs) are 'what if' tests: "an MI reflects the improvement in model fit that would result if a previously omitted parameter were to be added and freely estimated" [@curran-baueranalytics19]. There are as many MIs for a model as excluded parameters. In our case, the MIs are mostly loadings on other factors&mdash;for instance, AMB3's loading on HI. What's interesting, then, are the items that, when loaded on a different factor, improve the model significantly. MIs represent potential changes in $\chi^2$, so larger values imply a larger $\chi^2$ and improved model fit.

There are nearly 500 modification indices, so I truncated the full results to just a list of the 10 largest factor loadings in rank order.

```{r}
fit.1 %>%
  modificationIndices(sort. = T, op = "=~") %>%
  head(10) %>%
  kable
```

HI1, HI3, HI4 appear to not belong in HI! Let's take a look at the items:

- HI1: Always rushed
- HI3: Act immediately under pressure
- HI4: Always hurry

The MIs show that HI1 may belong TP. HI1 conceptually does seem to fit in TP because it's in the form of a participle adjective, whereas HI is conceived as behavior.

HI3 may also belong in TP for the obvious reason that it says "under PRESSURE", which not-so-gently reminds me of "time PRESSURE".

HI4 may belong in ANX according to its MI, but I don't see an obvious reason why. This may be a case where the MI suggests a change that's not supported by theory.

### Residuals

```{r}
mtx.1.a <- resid(fit.1)$cov

mtx.1.a %>%
  kable(digits = 3, row.names = T) %>%
  kable_styling(font_size = 13) %>%
  scroll_box(width = "100%", height = "500px",
             fixed_thead = list(enabled = T, background = "#63a0e1"))
```

What I would be curious to see here is whether any of the residuals represent statistically significant changes. The largest residual is for the correlation between HI6 and TP5. I'm just going to do a quick paired-r test using Fisher r-to-z transformations on the observed and predicted values for this correlation.

```{r}
fun.1 <- function(var1, var2) {
  r <- mtx.1[var1, var2]
  t <- paired.r(r, r + mtx.1.a[var1, var2], n = 211)
  print(str_glue("z: {round(t$z, 3)}, p: {round(t$p, 3)}"))
}

fun.1("tp5", "hi6")
```
Right, so that's a significant change, as expected for a residual over .2. TP5 is "Faced with daily deadlines at work" and HI6 is "Hurry more than others". A high residual means that the factors these items are loading on are more correlated than the items themselves. And I think that's not surprising in this case; time pressure and hurried/impatient behavior seem conceptually related to me while deadlines at work and hurrying more than others are not closely related.

Why don't we look at one more before moving on? I'll take a low residual to see how that translates into fit between loadings and factors. CD2 and ANX3 have a residual of just .021. I doubt that's significantly significant, but, oh, what the heck.

```{r}
fun.1("cd2", "anx3")
```
Nope. Just nope.

Now let's look at the items. CD2 is "Hard-driving and competitive when younger", and ANX3 is "Feel uneasy and restless". The items are not closely related, and the correlation between them reflects that. And we already know that the correlation between CD and ANX is relatively low. Two low correlations produce a low residual. Makes sense to me.

However, I do wonder if there is a floor effect in play. What I mean is, are two low correlations going to have a smaller difference than two high correlations? Since correlations are coefficients in linear equations with (assumed) constant variance, I really don't think it should be an issue.

### Measurement Model Fit

Before we put this model away for a bit, let's look at its overall fit. As with the models in the previous assignment, I'll pull up the $\chi^2$, RMSEA, and TLI.

```{r}
fitMeasures(fit.1, fit.measures = c("chisq", "df", "pvalue", "rmsea", "tli")) %>%
  round(3) %>%
  kable(align = "l")
```

Good $\chi^2$, so-so RMSEA, and an unacceptably low TLI. I'm going to call it a poor model. My hopes were not very high after seeing some of the issues above, so I'm not surprised. Oh well.

## 2. Orthogonal Measurement Model

```{r}
fit.2 <- cfa(chr.1, sample.cov = mtx.1, sample.nobs = 211, std.lv = T, orthogonal = T)
```

I checked this model against the results in LISREL and found that they were similar, but not identical. I will proceed nonetheless, but expect some differences on the order of rounding error.

As usual, I will check the $\chi^2$, RMSEA, and TLI.

```{r}
fitMeasures(fit.2, fit.measures = c("chisq", "df", "pvalue", "rmsea", "tli")) %>%
  round(3) %>%
  kable(align = "l")
```

The $\chi^2$ statistic is still showing as significant, but the RMSEA and TLI statistics have degraded considerably.

Now I will take a look at the $\chi^2$ difference test. This test should tell us whether there is sufficient improvement in fit to justify a loss of parsimony (i.e., more parameters). The test is simple: take the difference of the two models' $chi^2$ statistics and the difference in their degrees of freedom [@pavlov_etal20]. Then simply refer to a $\chi^2$ distribution.

```{r}
# M0 is nested within M1
fun.2 <- function(M0, M1) {
  D <- fitMeasures(M0, "chisq") - fitMeasures(M1, "chisq")
  df <- fitMeasures(M0, "df") - fitMeasures(M1, "df")
  p <- pchisq(D, df, lower.tail = F) %>%
    set_names("p")
  map_dbl(c(D, df, p), ~ round(., 3))
}

fun.2(fit.2, fit.1)
```
There is a significant difference between the fit of the models, with the intercorrelated model (from section 1) outperforming the orthogonal model. This tells us that there are indeed meaningful correlations between the factors, which bodes well for the structural model to follow.

## 3. Structural Equation Model with Latent Variables

This is the most complete model, incorporating both latent variables with multiple items and structural relationships.

### Estimation in R

I will reproduce the analysis in LISREL by combining the previously specified measurement and structural models into a single model. I will check the $\chi^2$ statistic as a quick spot check to compare it with the LISREL output.

```{r}
chr.3 <- '
    # measurement model
    amb =~ amb1 + amb2 + amb3 + amb4 + amb5
    cd =~ cd1 + cd2 + cd3 + cd4
    tp =~ tp1 + tp2 + tp3 + tp4 + tp5
    hi =~ hi1 + hi2 + hi3 + hi4 + hi5 + hi6
    anx =~ anx1 + anx2 + anx3 + anx4 + anx5 + anx6 + anx7 + anx8
    
    # structural model
    cd ~ amb
    tp ~ amb + cd
    hi ~ tp + cd
    anx ~ tp + hi
'

fit.3 <- sem(chr.3, sample.cov = mtx.1, sample.nobs = 211, std.lv = T)

fitMeasures(fit.3, "chisq")
```
It's within a similar range to previous models, so I will proceed.

### Comparison to Measurement Models

First, I need to compare the measurement component of the model with the models from sections 1 and 2 above.

#### Item Loadings in Full Model

If I understand the difference between "standardized" and "completely standardized" correctly, the former standardizes only the latent variables while the latter standardizes both the latent variables and their indicators. `lavaan` offers the "completely" standardized solution by default.

Now, simply adding a structural model should not change the measurement model underpinning it, so I will be most curious to see whether there has been any change in the item loadings from [the model in section 1](#item-loadings-in-measurement-model).

```{r, message = F}
standardizedSolution(fit.3, se = F, zstat = F, pvalue = F, ci = F) %>%
  rename(full = "est.std") %>%
  left_join(
    standardizedSolution(fit.1, se = F, zstat = F, pvalue = F, ci = F) %>%
              rename(measure = "est.std")
    ) %>%
  filter(op == "=~") %>%
  mutate(dif = round(full - measure, 3)) %>%
  kable
```

The column on the right is simply the difference between the loadings in the measurement model and in the full model. Overall, the items look stable, so the only issues are the same as before (e.g., TP5, ANX2).

#### Full Model Fit

The $\chi^2$-statistic, RMSEA, and TLI are below:

```{r}
fitMeasures(fit.3, c("chisq", "df", "pvalue", "rmsea", "tli")) %>%
  round(3) %>%
  kable(align = "l")
```

Not great, but not terrible for the models we've been running. The RMSEA is almost good, but the TLI is very poor.

#### $\chi^2$ Difference Tests

I'll start by comparing this model to the the less restrictive orthogonal model.

```{r}
fun.2(fit.2, fit.3)
```
Good start. It definitely performs better than the orthogonal model.

Next, I will compare it to the intercorrelated measurement model.

```{r}
fun.2(fit.3, fit.1)
```
It did not perform better, so it's not an improvement in terms of explaining variance in the data. However, introducing a full structural model allows us to make causal arguments about the relationships between variables, so I think it is still worth proceeding with the analysis of this model.

### Comparison to Structural Models

I will first look at this model's structural parameters on their own, then compare them with the structural parameters in the three models from the previous assignment.

#### Structural Parameters

```{r}
parameterEstimates(fit.3, ci = F) %>%
  filter(op == "~") %>%
  kable
```

Unlike in previous models, multiple structural parameters are non-significant&mdash;in fact, more than half. Only the paths between AMB and CD, TP and HI, and HI and ANX are supported by this analysis.

#### Comparisons to Previous Structural Models

I'll pull a table with all the parameter coefficients side-by-side.

```{r, message = F}
load(here('data', 'hw11data.RData'))

fit.3 %>%
parameterEstimates(se = F, zstat = F, pvalue = F, ci = F) %>%
  rename(full = "est") %>%
  left_join(
    parameterEstimates(fit.reliabilities, se = F, zstat = F, pvalue = F, ci = F) %>%
      rename(incorporated = "est") %>%
      mutate_at(1:3, ~ str_remove(., "_.*"))
    ) %>%
  left_join(
    parameterEstimates(fit.disattenuated, se = F, zstat = F, pvalue = F, ci = F) %>%
      rename(disattenuated = "est")
    ) %>%
  left_join(
    parameterEstimates(fit.observed, se = F, zstat = F, pvalue = F, ci = F) %>%
      rename(path_analysis = "est")
    ) %>%
  filter(op == "~") %>%
  mutate_at(4:7, ~ round(., 3)) %>%
  kable
```

There are some dramatic differences here. The effect of AMB on CD and TP on HI are much stronger in the full model than in any others. They're so strong, in fact, that I recall my earlier complaint in the [path analysis assignment](https://dsethlewis.github.io/809site/hw/hw10.html#f.-conclusions) that AMB/CD and TP/HI seem more like facets of the same construct than different variables.

If we consider that the present model is the 'best' test of these hypothesized paths because it most thoroughly incorporates the raw measurement data, then it is fair to say that only the AMB-CD and TP-HI paths are strongly supported. The HI-ANX path tested as significant in this model, but it's a weak effect that just barely meets the bar for significance.

I would have to say the other paths are not supported. They have only very weak effects that do not test significant. That they appear larger in the other models diminishes my opinion of those models but does not convince me that the full structural model is incorrect.

## Conclusions

The steady drip of bad news for Theoretical Model A continues.

The measures have low reliability (possibly due to inconsistent items), and the factor model is unconvincing (especially HI).

Without a solid factor model, it's difficult to make substantive interpretations of the structural model. But were we to do so anyway, we would find that the hypothesized model does not correspond to the data. Five of seven paths are insignificant or weak, and the remaining two paths' strength can be attributed to conceptual similarities rather than causal relationships.

That said, there clearly are some true relationships in the data. Perhaps a respecified model (informed by theory) could produce cleaner factors and significant structural parameters.

## References

```{r results = "hide"}
bbt_write_bib("biblio.json", bbt_detect_citations("hw12.Rmd"), overwrite = TRUE)
```

